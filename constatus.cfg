logfile = "test.log";
log-level = "info";

# This setting selects what library to use to resize/scale the video
# images (when used).
# "regular" is just resize as is.
# Use "crop" when not to scale but to crop, in that case
# resize-crop-center selects if the result should be centered.
resize-type = "regular";
resize-crop-center = true;

# how to handle failures of any kind
# note that a 'source'-object can also have a failure-handling instance.
failure-handling = {
# mode, can be either "message" or "nothing". nothing returns a black image.
	mode = "message";
# jpeg-image to show on the background (optional)
	bitmap = "";
# message to show when the source fails. Note that cameras that return
# some form of JPEG (e.g. MJPEG) which is corrupted may give a 'gray image'
# instead of an error.
	message = "Camera down since %c";
# where to put the message
	position = "center-center";
# position can be:
#  - upper-left
#  - upper-center
#  - upper-right
#  - center-left
#  - center-center
#  - center-right
#  - lower-left
#  - lower-center
#  - lower-right
#  - xy
#    e.g.: position = 'xy:100,200'
#    this is a relative position; a negative value will wrap
#  - axy
#    e.g.: position = 'axy:100,200'
#    this is an absolute position
};

instances = ({
	instance-name = "my instance name";
	# optional, show in web-interface:
	instance-descr = "something descriptive";

	source = {
		id = "1-1";
		descr = "video4linux source";
		type = "v4l";
		device = "/dev/video0";
		width = 352;
		height = 288;
	# If the camera supports JPEG output AND no post-processing ("filters")
	# are applied nor any motion detection, then setting this to true may
	# lower cpu usage.
		prefer-jpeg = false;

	# Enable controling of contrast/saturation/etc in the user interface.
	# Note: runs a software implementation (relatively slow!) if the hardware
	# has no support for it.
		enable-controls = true;

	# What program/script to start when the video-source fails. E.g.
	# something that restarts the camera.
		exec-failure = "";

	# how long before a camera is considered to be off-line (in seconds)
	#	timeout = 2.5;

	# When the video-source is unreliable, enabling the watchdog can let
	# constatus try to restart it. The parameter sets after how many seconds
	# to try to restart the camera. Use "-1.0" to disable this feature.
		watchdog-timeout = 3.0;

	# Start/stop this \"source\" depending on the demand. E.g. connections
	# to ip-cameras will be stopped when no-one is viewing. Note that when
	# a motion-trigger is configured, that this setting then effectively is
	# a no-op.
	# Note: when this is set to true, opening a view to this source may
	# have (considerable) delay before anything is shown! (depending on the
	# latency of the source)
	# This functionality can be useful for example when using constatus as
	# a portal to one or more cameras. It can then e.g. hide the real IP-
	# address and/or interface streaming protocols (for example h.264 to
	# mjpeg).
		on-demand = false;

	# libcamera is https://libcamera.org/
	#	type = "libcamera";
	# Camera-name is e.g. "imx477" for the new HD camera of the raspberry pi.
	# The libcamera package contains a program called "cam". With "cam -l"
	# you get a list of cameras connected to your system.
	#	device = "camera name";
	# Using the "cam" program from libcamera, you can get a list of controls
	# by invoking it with "--list-controls".
	#	controls = ({
	#			name = "contrast",
	#			data = "1.5";
	#		},
	#		{
	#			name = "brightness",
	#			data = "1.1";
	#		})

	# Retrieve a JPEG image from a specific URL, each interval/fps.
	#	type = "jpeg";
	#	url = "http://192.168.64.139/image.jpg";
	#	http-auth = "";

	# Retrieve from PipeWire source.
	#	type = "pipewire";
	#	id = ...id of the device (or -1)...;

	# Check if a file in the filesystem
	#	type = "jpeg-file";
	#	path = "/home/pi/test.jpg";
	
	#	type = "rtsp";
	#	url = "rtsp://iprobocam.marmitek.com/mpeg4";
	# Default is retrieve the rtsp stream over UDP. If you see a lot of
	# garbage (or the camera does not respond at all over UDP), then you
	# can switch tcp to true.
	#	tcp = true;

	#	descr = "an MJPEG source";
	#	type = "mjpeg";
	# Use broken-mjpeg here if mjpeg doesn't work: you'll see a message "camera is down". In that case, try broken-mjpeg.
	#	url = "http://webcam.st-malo.com/axis-cgi/mjpg/video.cgi?resolution=352x288";

	#	descr = "a plugin source";
	#	type = "plugin";
	#	source-plugin-file = "source-plugins/demo.so.0.1";
	#	source-plugin-parameter = "";

	#	descr = "source with a delay";
	#	type = "delay";
	#	# how many frames in the past. combined with max-fps this selects how many seconds in the past.
	#	n-frame = 12;
	#	# ID of the original source to delay
	#	delayed-source = "1-1";

	#	descr = "a pixelflood source";
	#	type = "pixelflood";
	#	listen-port = 5004;
	#	pp = "tcp-txt";
	#	 -or-
	#	pp = "udp-bin";
	#	pixel-size = 1;

	#	descr = "static image, for testing";
	#	type = "static";

	# -1 is no limit
		max-fps = -1.0;

	# if all targets and http-servers want to use the resized picture, then
	# resize it here at the source (for cpu efficiency)
	# These values are number of pixels horizontal and vertical.
	# This does not apply for the pixelflood source.
	# -1 means: do not resize
		resize-width = 640;
		resize-height = 360;

	# if the source is an https-URL with an invalid SSL certificate, then
	# this switch lets you ignore that certificate
		ignore-cert = true;

	# Filters directly at the source-module apply to all consumers (like the
	# http-servers, streamers, targets, etc).
		filters = (
				{       
					type = "v-mirror";
				}
			)

		failure-handling = {
	# mode, can be either "message" or "nothing". nothing returns a black image.
			mode = "message";
	# jpeg-image to show on the background (optional)
			bitmap = "";
	# message to show when the source fails
			message = "Camera/video source down since %c";
	# where to put the message
			position = "center-center";
		};
	}

	http-server = (
	# You can have 0 or more HTTP servers. They must all listen on other
	# adapter/port pairs that are also not used by other software on the
	# system.
			{
				id = "1-2";
				descr = "stream only, motion compatible";

	# What IP-address/TCP port to listen on.
				listen-adapter = "0.0.0.0";
				listen-port = 8081;

	# Set these to the filenames of the key/certificate file to enable
	# enable https.
				key-file = "";
				certificate-file = "";

	# File with a "message of the day" that will be shown on the main-
	# menu page. Leave empty to omit.
				motd = "";

	# Path to the stylesheet.css-file in your local filesystem (e.g. not an
	# URL). E.g. /usr/local/share/constatus/stylesheet.css
	# This allows you to use your own stylesheet which may, for example, add
	# a logo or so.
				stylesheet = "stylesheet.css";

	# Optional: authentication-method. Either none, file or pam.
	#			http-auth-method = "";
	# This is required for method "file". The file is a text-file with 2
	# lines: first is username, second is password.
	# 			http-auth-file = "...";

	# Use -1 for show all frames available (that would use more bandwidth).
	# Value cannot be higher than the "max-fps" -setting in the source.
				fps = 5.0;
	# For JPEG-frames, set the quality. 100 = best, 0 = worst
				quality = 75;

	# For streams, maximum time (in seconds) before the connection is closed.
				time-limit = -1;

	# What to do if a frame is missing.
				handle-failure = true;

	# If you wish to resize the pictures, then you can do so with these
	# parameters (-1 for disable).
				resize-width = -1;
				resize-height = -1;

	# When enabled, then the HTTP-server will send HTTP-headers but without
	# waiting for the full request. That is how motion did it at some point.
				motion-compatible = true;

	# When enabled, allows you to stop/start/etc services.
				allow-admin = false;

	# For web-access to the archive of recordings.
				archive-access = false;
	# Path to the recordings. Usually this is the same as the path used in
	# the target(s) - see below.
				snapshot-dir = "./";
	# When enabled, also the sub-directories of snapshot-dir are given
	# access to.
				dir-with-subdirs = false;

	# Each HTTP-server can have 0 or more filters.
				filters = (
	# The "text"-filter adds a text to the video stream.
	# You can use the escapes as supported by "strftime" (see the man page).
	# Other escapes:
	# - $http-viewers$ number of viewers to the web server
	# - $pixels-changed$ number of changed pixels as detected by the motion trigger
	# - $motion$ replaced by a helpful text if any motion is detected
	# - $descr$ replaced by the descr="" of the source
	# - $id$ replaced by the id="" of the source
	# - $fps$ is the moving average (over 5s) of the FPS of the current source
	# - $exec:cmd$ invokes 'cmd' and replaces it with its output. cmd should
	#              output 1 line of text and stop immediately after that.
	# - $file:path$ retrieves contents from file pointed to by 'path'
	# - $ts$ time of frame, in microseconds since 1970
	# Position can be lower/upper/center-left/center/right.
						{         
							type = "text";
							text = "%c";
							position = "lower-right";
						},
	#					{         
	# Like "text" but with a specific font, size, RGB color and pixel-location.
	#						type = "scaled-text";
	#						text = "%c";
	# Path to the font-file to use.
	# The font-file in this example is from the fonts-freefont-ttf package.
	# These texts have escapes. E.g. $Crrggbb$ sets the foreground color of the text
	# that follows it. rrggbb are hexadecimal values. $u$ toggles underline and $i$
	# toggles inverted background.
	#						font = "/usr/share/fonts/truetype/freefont/FreeSerif.ttf";
	# Coordinate where to put the text. Use negative to use relative to the
	# right/bottom.
	#						x = 123;
	#						y = 123;
	# Maximum width of text (in pixels). Optional.
	#						w = 400;
	# Size of text in pixels.
	#						font-size = 15;
	# Draw a black box below the text.
	# 						background = true;
	# Defines the color to use. Default is white.
	#						r = 0;
	#						g = 0;
	#						b = 0;
	# You can also set:
	# 					 	rgb = "0,0,0";
	# or:
	# 						color = "yellow";
	# (known colors are: red, blue, green, black, white, magenta, cyan, yellow).
	# Wether to invert colors. Usefull when background color is not known on forehand.
	#						invert = false;
	# What color to use for background (optional!). Use bg-color, bg-rgb or bg-r/bg-g/bg-b.
	# Omit for no background color!
	# 					 	# bg-rgb = "0,0,0";
	#					},
	# This "filter" puts text over a video. For that it invokes the commandline
	# given in "exec-what". Then the last "n-lines" are shown.
	#					{         
	#						type = "exec-scroll";
	#						# here we follow some MQTT feed
	#						exec-what = "mosquitto_sub -h revspace.nl -t '#' -v";
	#						n-lines = 5;
	#						font = "/usr/share/fonts/truetype/freefont/FreeMono.ttf";
	#						font-size = 25;
	#						x = 25;
	#						y = 100;
	# How fast to scroll horizontally, in pixels per iteration.
	#						scroll-speed-h = 2;
	# Defines the color to use. Default is white.
	#						color = "black";
	#						invert = false;
	#					}
	# external filter plugin
	#					{
	#						type = "filter-plugin";
	#                                               # filename
	#						file = "filter-plugins/demo.so.0.1";
	#                                               # any parameter for the plugin
	#						par = "";
	#					},
	# frei0r filter plugin
	#					{
	#						type = "filter-plugin-frei0r";
	#						file = "/usr/lib/frei0r-1/sharpness.so";
	#						pars = "";
	#					},
	# horizontal mirror
	#					{       
	#						type = "h-mirror";
	#					},        
	# vertical mirror
						{       
							type = "v-mirror";
						}
	# Convert an image to gray scale.
	#					{       
	#						type = "grayscale";
	#					},        
	# Noise-filter
	#					{
	#						type = "neighbour-noise-filter";
	#					},
	# Boosts the contrast
	# 					{
	# 						type = "boost-contrast";
	# 					},
	# Place a PNG image over the recorded video
	#					{
	#						type = "overlay";
	#						picture = "overlay-test.png";
	#						x = 10;
	#						y = 10;
	# Instead of x/y coordinates, you can also set a 'position' here:
	#                                               # position = 'upper-left';
	#					},
	# Place an (animated) GIF or MNG image over the recorded stream
	#					{
	#						type = "gif-overlay";
	#						picture = "overlay-test.gif";
	#						x = 10;
	#						y = 10;
	#                                               # position = 'upper-left';
	#					},
	# Mask of anything not in the masking bitmap (for e.g. privacy).
	# selection-bitmap must a pbm file or a (black & white-) png file.
	#					{       
	#						type = "apply-mask";
	#						selection-bitmap = "bitmap.pbm";
	# When soft-mask is enabled, the masked-off parts are replaced by the average
	# color of the masked part. Else, it is replaced by black.
	#						soft-mask = false;
	#					},
	# Draw a box with a certain color. Can also be used for privacy masking but
	# without the need of a bitmap-file.
	#					{       
	#						type = "draw";
	#						x = 10;
	#						y = 10;
	#						w = 20;
	#						h = 15;
	#						rgb = "0,0,0";
	#					},
	# Show only the parts that have moved.
	#					{       
	#						type = "motion-only";
	#						# bitmap is optional, set to "" to omit
	#						selection-bitmap = "bitmap.pbm";
	#						noise-factor = 32;
	#					},
	# Draw a box around the movements.
	#					{
	#						type = "marker";
	# Red, red-invert, invert or color.
	#						mode = "invert";
	# When mode is "color", set the red, green and blue values with this parameter:
	#                                               pixels-color = "255,255,0";
	# Box, cross, circle or border.
	#						marker-type = "box";
	# Thickness of marker.
	# 						thick = 5;
	#						selection-bitmap = "bitmap.pbm";
	#						noise-factor = 32;
	# What %% of pixels need to be changed before the marker is drawn
	#						pixels-changed-percentage = 1.6;
	# Set to true when you want to use the "bitmap"-filter with "$motion-box$".
	#						remember-motion = false;
	#					},
	# Chroma-keying ("green screen")
	#					{       
	#						type = "chroma-key";
	#						# green will be replaced by the video-source
	#						# from an other instance. select that instance
	#						# here.
	#						replace-by = "some other instance";
	#					}
	# This makes a copy of a certain part of the incoming stream. It can be pasted using
	# "bitmap", see below. Copies are rememberd under the name as configured by
	# "rembember-as".
	#					{       
	#						type = "copy";
	#						remember-as = "$window$";
	#						x = 0;
	#						y = 0;
	#						w = 25;
	#						h = 20;
	#					}
	# Put a bitmap stored elsewhere in the current stream. A "paste" function.
	# E.g. "$motion-box$" from "marker" (set "remember-motion" to true in filter "marker")
	# or from "copy".
	#					{       
	#						type = "paste";
	#						which = "$motion-box$";
	#						x = 0;
	#						y = 0;
	#					},
	# Starts an LCDPROC server which is then overlayed over the video stream.
	#					{
	#						type = "lcdproc";
	# Network interface to listen on.
	#						listen-adapter = "0.0.0.0";
	# Select a font to use. Best results with monospaced fonts.
	#						font = "/usr/share/fonts/truetype/msttcorefonts/Courier_New.ttf";
	# Coordinates to place the result
	#						x = 1;
	#						y = 1;
	# Dimensions of the result.
	#						w = 1278;
	#						h = 718;
	# "Virtual LCD panel dimensions", e.g. how many characters are visible per row.
	#						n-col = 40;
	#						n-row = 10;
	# Text-color. Default is white.
	#						r = 0;
	#						g = 0;
	#						b = 0;
	# Wether to invert colors. Usefull when background color is not known on forehand.
	#						invert = false;
	# Switch interval. When to switch between "screens". In milliseconds.
	# 						switch-interval = 3500;
	# 						# 3500 = 3.5 seconds
	#					}
					);

	# Constatus can stream some meta-data to the web-interface. Currently (v4.3)
	# that are "motion detected" messages and addresses of people starting to
	# what a stream (or stopping to do that).
	# For this it needs a websocket. With the following line you can configure
	# on which port it should listen.
				websocket-port = 4000;
	# If Constatus is behind a proxy (like nginx or apache), the URL via which
	# the websocket is reachable may be different from the one on which the
	# program is running. In that case you can configure that URL here.
	#			websocket-url = "ws://bla:123/blip";
	# The websocket interface can be useful to see immediate notifications when
	# motion is detected. But the notifications of addresses of people starting
	# to follow a stream may not be. If you *don't* want to see those, set this
	# parameter to 'true'.
				websocket-privacy = true;
			},
			{
				id = "1-3";
				descr = "admin interface";
				listen-adapter = "0.0.0.0";
				listen-port = 8082;
				fps = 5.0;
				quality = 75;
				time-limit = -1;
				resize-width = -1;
				resize-height = -1;
				motion-compatible = false;
				allow-admin = true;
				archive-access = true;
				snapshot-dir = "./";
				filters = (
						{         
							type = "text";
							text = "my webcam $http-viewers$ $pixels-changed$";
							position = "upper-left";
						},
						{         
							type = "text";
							text = "%c";
							position = "lower-right";
						}
					);
			}
		);

	# these plugins can be used to store specific meta-data in
	# generated files. you can let them generate e.g. $bla$
	# escapes which you then can use in the add-text filter.
	#meta-plugin = (
	#	{
	#		plugin-file = "meta-plugins/gps.so.0.1";
	#		plugin-parameter = "localhost 2947";
	#	}
	#)

	motion-trigger = (
		{
			id = "1-4";
			descr = "motion trigger(s)";

	# If the "source" supports pan/tilt, then enabling this will make it
	# pan/tilt the camera depending on the movements.
	# This can be set for multiple "motion-trigger"s of one source, but
	# that may not work very well of course.
			pan-tilt = true;

	# Remember the first picture that triggered the motion. Store this as
	# a macro $...$ (see "copy" and "paste" below). Leave empty ("") to
	# disable.
			remember-trigger = "$trigger$";

	# While motion is detected, each pixel is first converted to grayscale.
	# Then the difference with the previous recording is calculated.
	# If the difference is bigger than the noise-factor, then the pixel is
	# counted...
			noise-factor = 32;
	# ..., then if the total number of pixels is >= the percentage of the
	# pixels selected by pixels-changed-percentage, then motion is
	# considered to be detected
			min-pixels-changed-percentage = 0.6;
	# unless more pixels have changed than this setting.
	# E.g. for preventing a lightswitch triggering the detection.
			max-pixels-changed-percentage = 80.0;
	# Note that these three parameters are not used when the motion trigger
	# plugin is selected.

	# If the motion has stopped, how many frames to record extra. A better
	# name would have been "post motion record duration".
			min-duration = 15;
	# How many frames to ignore all motion after the previous event has
	# stopped.
			mute-duration = 5;
	# How many frames to record and store before the motion has started.
			pre-motion-record-duration = 15;
	# How many frames should have motion before recording starts.
			min-n-frames = 1

	# At startup, how many frames to ignore before detecting motion.
			warmup-duration = 10;
	# Limit the number of frames per second to process. Set to -1 to
	# disable.
			max-fps = -1.0;

	# One can use external plugins for detecting motion.
			trigger-plugin-file = "";
			trigger-plugin-parameter = "";

	# A pgm file to mask which parts of the video frames to analyze.
			selection-bitmap = "";

	# Despeckle filter.
	# d = dilate (kernel size of 5, D is kernel size 9)
	# e = erode (kernel size of 5, E is kernel size 9)
			despeckle-filter = "dEeD";

	# Zero or more filters that are applied before the frames are analyzed.
	# Use filters to remove noise or despeckle etc. Using a filter that
	# adds texts or whatever may give/gives false positives. It is advised
	# to use e.g. neighbour-noise-filter, grayscale, average and/or boost-
	# contrast. To add other effects, add them to the filter() in the e.g.
	# targets-section.
			filters-detection = ( );

	# Programs to invoke when motion starts/stops. Leave empty ("") when not required.
			exec-start = "";
			exec-end = "";

	# You can let a motion-trigger also listen to an other motion-trigger.
	# That way multiple cameras can be triggered to all start recording when
	# one gets notified.
	# Leave empty to not connect!
			motion-source = "some-other-instance";

	# Schedule for when to detect motion. Remove to always detect.
	# This example detects on wednesday between 11:00:05 and 12:00:00
	# and 19 and 20 o'clock and also the whole thursday.
			schedule = ( "wed,11:00:05,12:00,on",
				     "wed,19:00,20:00,on",
				     "wed,19:22:00,19:22:10,off"
				     "thu,00:00:00,23:59:60,on"
				   )

	# Targets are the services that stream the frames to a disk-file or a network
	# service. See the section "targets" below for an explanation.
			targets = (
				{
					id = "1-5";
					descr = "motion output";
					path = "./";
					prefix = "motion-all-";
					quality = 75;
					restart-interval = 86400;
					fps = 5.0;
					override-fps = -1.0;
					format = "avi";
					stream-writer-plugin-file = "";
					stream-writer-plugin-parameter = "";
					exec-start = "";
					exec-cycle = "";
					exec-end = "";
					schedule = ( )
					# %p prefix
					# %Y year, %m month (number), %d day
					# %H hour, %M minute, %S seconds, %u microseconds
					# %q recording-number
					# %t camera id, %$ camera name
					# %{host} system hostname
					# %[key] replace by meta-element 'key'
					fmt = "%p%Y-%m-%d_%H-%M-%S.%u_%q";
					filters = (   
							{         
								type = "text";
								text = "my webcam $http-viewers$ $pixels-changed$";
								position = "upper-left"
							},        
							{         
								type = "text";
								text = "%c";
								position = "lower-right"
							}
						)
				}
			)
		}
	)

	# when a "source" has also audio recording capabilities, then that can be
	# monitored. when the audio reaches a certain level, it can trigger the
	# video-recording (see "motion-trigger" above). audio is processed in
	# samples of 0.1s
	audio-trigger = {
				id = "1-5";
				descr = "audio trigger";
				# threshold to see if what we record is noise
				# or real sound. the range is 0...32767
				threshold = 350;
				# if this many samples had a level above the
				# threshold, then the (video-)motion-trigger(s)
				# will be triggered to start recording
				min-n-triggers = 25;
				# ids of the video-triggers to trigger (comma
				# seperated)
				trigger-ids = "1-4";
			}

	# A service that writes the video stream that is recorded
	# to disk or a network service.
	targets = (
	# You can have 0 or more of these.
		{
			id = "1-6";
			descr = "write everything to disk";

	# Path to store the recordings in.
			path = "./";
	# Prefix for the filename.
			prefix = "all-";

	# In case of JPEG, quality of the compression. 100 is best, 1 is worst.
			quality = 75;

	# Split the file every restart-interval seconds.
			restart-interval = 86400;

	# If the source has no frame available but it was expected, this setting
	# sets if it should handle the error with a message or not (see 'failure'
	# definition in the source definition).
			handle-failure = true;

	# Limit a recording to this number of frames per second.
	# You can also use "interval = ..." here (which is 1.0 / fps). Using
	# interval allows you to create timelapse videos.
			fps = 5.0;
	# You can make files play faster by setting a value > 0 here. In this
	# example constatus will record 5 frames per second but the result will
	# play at 10fps and thus twice as fast.
			override-fps = 10.0;

	# Output format.
			format = "avi";
	# Can be:
	# - avi: (which is MJPEG underneath)
	# - ffmpeg: use ffmpeg to compress the data. all format supported
	#   by ffmpeg can be used. requires the following extra parameters:
	#		ffmpeg-type = "flv";
	#		ffmpeg-parameters = "";
	#   ffmpeg-type would be something like "mp4", "flv", etc.
	#   bitrate: how many bits per second to write. Depends on the
	#   codec, the resolution and the fps.
	# - plugin: use an external plugin to store the data
	#		stream-writer-plugin-file = "";
	#		stream-writer-plugin-parameter = "";
	# - extpipe: send a YUV420 stream to a pipe
	#   requires an extra parameter "cmd", e.g.:
	#		cmd : "mencoder -demuxer rawvideo -rawvideo w=%w:h=%h:fps=%fps -ovc x264 -x264encopts preset=ultrafast -of lavf -o %f.mp4 - -fps %fps";
	# - jpeg: store each frame as a seperate file
	#         useful for snapshots. e.g. remove fps=... and set interval=... and then set format="jpeg"
	# - pipewire: send each frame to a pipewire server
	#         comparable to 'video-loopback'
	# - vnc: VNC video stream
	#   requires two extra parameters:
	#               listen-adapter = "0.0.0.0";
	#               listen-port = 5901;
	# - pixelflood
	#   requires a couple of extra parameters:
	#               host = "0.0.0.0";
	#               port = 5004;
	#	dimensions of the pixelflood server:
	#		pf-w = 128;
	#		pf-h = 16;
	#	offset in the pixelflood server:
	#		x-off = 128;
	#		y-off = 16;
	#	pixelflood version:
	#	        pp = "tcp-txt"    the protocol version that accepts "PX x y rrggbb\n" via a TCP socket
	#	        pp = "udp-bin"    the protocol version that accepts a binary packet via a UDP socket
	# - as-a-new-source
	#   This exports the video-stream AFTER filters have been applied
	#   (and resizing has been performed) as a new source.
	#   requires two extra parameters:
	#               new-id = "some-id";
	#               new-descr = "this is visible in the web-interface";
	#   rotate picture 90 degrees?
	#		rot90 = false;
	# - gstreamer
	#   Feed the video stream to a gstreamer pipeline.
	#               pipeline = "appsrc name=\"constatus\" ...";
	#   Note that Constatus pushes RGB frames into the pipeline.

	# Scripts to invoke at the start, at the end or when the file is
	# rotated (exec-cycle).
			exec-start = "";
			exec-cycle = "";
			exec-end = "";

	# Filters to apply. See descriptions at the http-server section.
			filters = (   
					{         
						type = "text";
						text = "%c";
						position = "lower-right"
					}
				)
		}
	)

	# Constatus can "loop back" the video data back into
	# the Linux kernel so that other applications can monitor
	# the same source as well (see also 'pipewire' target).
	#video-loopback = {
	# device to loopback to
	#	device = "/dev/video2";
	# Select the pixel format.
	# Firefox wants YUV420. Other value is RGB24.
	#	pixel-format = "YUV420";
	# Limit the frame rate to this, -1.0 to disable.
	#	fps = 15.0;
	# Any filters you want to apply before the video data
	# streams into the loopback device.
	#	filters = (
	#		)
	#};
}
# , {
#       source = {
#		id = "3-1";
#         ...
#       }
#
#       etc
#
# }
)

# as everything in constatus, these are optional
global-http-server = (
# global web-interface
# gives access to all instances
	{
		id = "2-1";
		descr = "global admin interface";
		listen-adapter = "0.0.0.0";
		listen-port = 8070;
		fps = 5.0;
		quality = 75;
		time-limit = -1;
		resize-width = -1;
		resize-height = -1;
		motion-compatible = false;
		allow-admin = true;
		archive-access = true;
		snapshot-dir = "./";
		key-file = "";
		certificate-file = "";
# allow rest-calls to be executed
# if you want e.g. controls, then enable this
		is-rest = true;
		filters = (
				{         
					type = "text";
					text = "$descr$";
					position = "lower-left";
				},
				{         
					type = "text";
					text = "%c";
					position = "upper-left";
				},
				{         
					type = "text";
					text = "$motion$";
					# either upper-right/left/center, center-right/left/center or lower-right/left-center,
					# xy:x,y or axy:x,y
					# e.g. xy:123,45
					# xy: negative values are wrapped to the right/bottom
					# axy: image below 0 is cropped
					position = "upper-right";
				}
			)
	},
	{
		id = "2-2";
		descr = "rest interface";
		listen-adapter = "0.0.0.0";
		listen-port = 8071;
		fps = 5.0;
		quality = 75;
		time-limit = -1;
		resize-width = -1;
		resize-height = -1;
		motion-compatible = false;
		allow-admin = true;
		archive-access = true;
		snapshot-dir = "./";
		filters = ();
	}
)

# Comment out if you don't want a history-database and no
# automatic cleaning and such. It is also used for the dashboard
# functionality.
maintenance = {
	# URL of the MySQL database. Database must exist.
	# User must have rights to create tables. When the tables have
	# been set-up, read/write/update/delete rights are enough.
        db-url = "tcp://ipaddress/nameofdatabase";
        db-user = "...";
        db-pass = "...";

	# keep recorderd files 14 days, set to -1 to disable purge
	keep-max = 14;
	# Clean-up every 300 seconds, set to -1 to disable.
	clean-interval = 300;

	# Constatus can easily be monitored. For that it has a nagios
	# 3 and 4 compatible NRPE service.
	# E.g.:
	# /usr/lib/nagios/plugins/check_nrpe -H localhost -4 -n -c '1-1'
	# ...would check the status of a module with id "1-1".
	# /usr/lib/nagios/plugins/check_nrpe -H localhost -4 -n -c '%ALL%'
	# ...will check all modules in the Constatus system for problems.
	# Comment out (or set to -1) to disable.
	# Note that you will need the "-n" flag for check_nrpe to disable
	# TLS.
	nrpe-service = 5666;
	# you can bind the service to a specific adapter
	# nrpe-service-adapter = "::1";
}

# display using http://host:port/view-view?id=...
# This needs a global-http-server to be enabled. Also the filters to be
# applied are configured in the global-http-server.
# The html-types cannot have "targets".
#views = ({
#		id = "view-1";
#		type = "html-grid";
#		descr = "HTML grid view";
#		# number of columns of streams
#		grid-width = 2;
#		# number of rows of streams
#		grid-height = 1;
#		# use -1 for automatic
#		width = 1280;
#		height = 800;
#		# id's of sources to display
#		sources = ( { id="1-1"; }, { id="3-1"; } )
#	},
#	{
#		id = "view-2";
#		type = "source-switch";
#		descr = "switching between sources";
#		# use -1 for automatic
#		width = 1280;
#		height = 800;
#		# id's of sources to display
#		sources = ( { id="1-1"; }, { id="3-1"; } )
#		switch-interval = 5.0;
#		# this option is for source-switch only
#		auto-shrink = true;
#		# targets are extra. a view is visible in the
#		# global http-server but source-switchers can
#		# also store the stream to e.g. a file. this
#		# is optional.
#		targets = (
#			{
#				id = "view-2-1";
#				descr = "view output";
#				path = "./";
#				prefix = "view-";
#				quality = 75;
#				restart-interval = 86400;
#				fps = 5.0;
#				override-fps = -1.0;
#				format = "avi";
#				filters = (   )
#			}
#		)
#		# views of type 'source-switch' and 'all' can send
#		# the result to the loopback device
#		# video-loopback = {
#		#	device = "/dev/video2";
#		#	pixel-format = "YUV420";
#		#	fps = 15.0;
#		#	filters = (
#		#		)
#		# };
#	},
#	{
#		id = "view-3";
#		type = "all";
#		descr = "all sources in 1 grid";
#		width = 640;
#		height = 480;
#		sources = ( { id="1-1"; }, { id="3-1"; } )
#		grid-width = 2;
#		grid-height = 1;
#		targets = ( )
#	},
#	{
#		id = "view-4";
#		type = "pip";
#		descr = "picture in picture";
#		# puts "3-1" in "1-1"
#		sources = ( { id="1-1"; }, { id="3-1"; position="upper-right"; } )
#		# to what size to shrink the image
#		percentage = 20;
#		targets = ( )
#	},
#	{
#		id = "view-5";
#		type = "3D";
#		descr = "3D view";
# Packing sets how the 2 images are combined. Which to choose depends
# on either the monitor or the glasses you use.
#		packing = "side-by-side";
#		# packing = "top-bottom";
#		# packing = "alternating-lines";
#		# packing = "alternating-columns";
#		# packing = "checkerboard";
#		# packing = "red-green";
#		# packing = "red-blue";
# You must select two sources to display. The first one is for the left
# eye, the second for the right eye.
#		sources = ( { id="1-1"; }, { id="3-1"; })
#	}
#	{
#		id = "view-6";
#		type = "html-all";
#		descr = "all sources in one view (using html)";
#		width = 1280;
#		height = 800;
#})

# If you build constatus with SDL2, then you can let it show a video-
# stream in one (1) window (this limitation is by SDL2 which does not
# allow threading in windows).
#guis = ({
#	id = "2-1";
#	descr = "SDL";
# # SOURCE(!)-name (NOT instance name: that way you can select
# # views as well (not html-views))
#	source = "view-4";
#	handle-failure = true;
# # window size:
#	target-width = 1280;
#	target-height = 720;
#	fps = 5.0;
#	filters = (
# # any filters...
#	);
#});

# This can announce video-stream(s) on the network via UPnP.
#announcers = ({
#	id = "unpn";
#	descr = "UPNP announcer";
# These are IDs of HTTP-servers. Note that they need to have a
# valid adapter IP-address configured for this to work. Comma
# seperated list.
#	announce-ids = "3-1,3-2";
# Network interface(s) to announce on. Comma seperated.
#	network-interfaces = "eth0,wlo1";
#})
